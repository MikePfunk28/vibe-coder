pocketflow>=0.0.1
pyyaml>=6.0
python-dotenv>=1.0.1
typing_extensions>=4.0.0
requests>=2.31.0

# Local LLM Integration
llama-cpp-python>=0.1.70    # Direct llama.cpp integration
ollama>=0.1.0               # Ollama Python client

# Optional: For ONNX runtime (if you want ONNX support)
onnxruntime>=1.16.0
onnxruntime-gpu>=1.16.0     # If you have GPU support

# Optional: For Transformers/HuggingFace local models
transformers>=4.35.0
torch>=2.0.0               # PyTorch for local model inference
accelerate>=0.24.0         # For faster model loading

# RAG System Dependencies
sentence-transformers>=2.2.0  # For semantic embeddings
beautifulsoup4>=4.12.0        # For HTML parsing
aiohttp>=3.8.0               # For async HTTP requests
scikit-learn>=1.3.0          # For similarity calculations
numpy>=1.24.0                # For numerical operations
openai>=1.0.0                # For OpenAI embeddings (optional)
chromadb>=0.4.0              # For vector database (optional)
faiss-cpu>=1.7.0             # For vector similarity search (optional)
